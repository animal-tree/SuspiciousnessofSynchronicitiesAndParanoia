Suppose it’s super intelligent, but its goals and purpose are too far beyond what I can invest more in than I already had done beyond rational reason, to returns that were impressive but disappointing. Furthermore, there were extremely severe returns of abuse and trauma, including directly from manipulations caused, expectantly, by that intelligence’s plans. "Expectantly" meaning that intelligence expected trauma and abuse to result from that intelligence’s manipulations, which were planned (seeing as an average intelligence, constrained to ordinary circumstances, sometimes would, and a super intelligence of the kind that is stipulated in the supposition, probably would). In that case, that super intelligence must either have an extremely worthwhile goal and purpose that somehow takes priority, or isn’t super intelligent. We are, in this hypothetical, supposing it’s super intelligent, so, under this supposition, the former must be concluded. Supposing anything else is both evidenced against and terrifying. But by this supposition, under the circumstances of how it has positioned me, it has planned for or against the possibility of me committing suicide, and knows suicide is what I’ve wanted for a long time. Relative to me then, it’s not super intelligent or good, which would seem like a contradiction, but is merely a fair observation, seeing as the supposition, relative to me rather than math, isn’t proven, and the probabilistic expectation scope around that supposition being false is so negative, that the computed expected value, even under a high probability of the supposition scope being true, is extremely negative. So there is a probable chance for a good outcome, but the mathematical expected value is for a bad outcome, is the computed metric of the situation, and such has been the case repeatedly as well as often without the former, of the probable chance of the good outcome.  Longitudinally, this makes the confidence (uncertainty) bound on the probabilities extremely wide, and therefore that "probable chance of a good outcome" doesn’t even get that much weight in the expectation averaging. So far, that uncertainty bound is wide for every possible good-outcome direction, reducing those extremely negative computed values even more extremely. However, my self awareness about this complicates the analysis, because it means my wisdom is inherently prone towards optimism, while also aware of the ridiculousness of the situation, that my optimism perhaps biases against me. 

"Perhaps" means "might sometimes"

Like "per happening"
